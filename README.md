# Таскаут – прототип платформы для оптимизации поиска работы на фрилансе
Последняя версия после тюнинга гиперпараметров. При запуке neural_network/BERT/train.py после клонирования репозитория можно получить схожий результат в 91% точности


На что можно обратить внимание в исследованиях:

### 1. Создание простой нейронной сети со свёрточными слоями
`neural_network/CNN/model/CNNmodel.py`\n
Обучение проводилось с нуля, максимальная точность 83%. Направление для продакшена не совсем актуальное, но было необходимо для проверки точности и скорости работы лёгкой сети\n

### 2. Создание сети на основе кастомного BERT
Написана обёртка для продвинутого обучения. Идея была в следующем: добавляем слой классификации, на первой эпохе обучаем только его. Далее тюним порядок разморозки слоёв для получения более высокого результата\n
`neural_network/BERT/models/custom_bert.py`\n
Эксперимент не удался, точность на уровне стандартной обёртки\n

### 3. Улучшение токенизатора
`neural_network/BERT/utils/tokens.py`\n
Некоторые слова разбиваются на кусочные токены, вроде ['ян', '##де', '##кс'] . Добавляя цельные слова из датасета возможно увеличить процент точности\n
В этом случае точность увеличилась на 2%

### 4. Валидация данных с помощью недообученной модели
`neural_network/BERT/test.py`\n
В разметке участовал только один человек (я), поэтому вполне мог сделать ошибки. Обучив BERT на одной эпохе получим достаточно точное распознавание по популярным экземплярам\n
Запустив тест на обучающей выборке, можно увидеть ошибки не только модели, но и свои. Спустя пару итераций датасет был улучшен



## Контакты
E-mail: artemgusevw@mail.ru
Telegram: @crayfos
